{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive simulation tutorial part 2: Simulation\n",
    "\n",
    "This tutorial is intended to give an introduction to running simulations with Rational Speech Act (RSA) agents within the Lanag simulation framework. It is part of the Supplementary Information for *submitted*, which we will refer to as the *main paper*.\n",
    "\n",
    "## 1. Loading libraries\n",
    "First we need to load some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`com.markblokpoel::lanag-core:0.3.2`\n",
    "interp.load.cp(new java.net.URL(\"https://github.com/markblokpoel/lanag-ambiguityhelps/blob/jupyternotebooks-restructuring/binaries/lanag-ambiguityhelps-0.1.jar?raw=true\"))\n",
    "import $ivy.`org.plotly-scala::plotly-almond:0.7.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.markblokpoel.lanag.rsa.Lexicon\n",
    "import com.markblokpoel.lanag.ambiguityhelps.RSA1ShotInteraction\n",
    "import com.markblokpoel.lanag.ambiguityhelps.datastructures.InteractionData\n",
    "import com.markblokpoel.lanag.ambiguityhelps.experiments.uniform.UniformPairGenerator\n",
    "com.markblokpoel.lanag.ambiguityhelps.jupyterdisplayers.RSA1ShotDisplayers // Activates nice html printing\n",
    "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating agent pairs\n",
    "\n",
    "Key to the study reported in the main paper was running simulations across a wide variety agent pairs that differ in lexicon ambiguity, the asymmetry between their lexicons and their order of pragmatic inference. Order has been explained in [part 1](./rsa-tutorial-part1.ipynb) of the tutorials. Here, we show how to work with the agent pair generator classes. There are three such classes, corresponding to the three different generation methods reported in the  main paper (viz. uniform ambiguity, implemented in `UniformPairGenerator`), and in the Supplementary Information (viz. Procedure I implemented in `RandomPairGenerator` and Procedure II implemented in `StructuredPairGenerator`).\n",
    "\n",
    "We explain here `UniformPairGenerator`. The other generators are similarly structured. After completing this tutorial, you should be able to read the source code. To create an instance of `UniformPairGenerator` requires several parameters:\n",
    "\n",
    "* `vocabularySize`, the number of signals $|V|$\n",
    "* `contextSize`, the number of referents $|R|$\n",
    "* `changeResolution`, a parameter between 0 and 1. Lower values create better coverage of the domain (cf. Figure 3 in the main paper).\n",
    "* `sampleSize`, the number of samples generated per point in parameter space (this will become clear in a moment)\n",
    "* `beta`, the beta parameter passed on to `RSA1ShotAgent`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val cpg = new UniformPairGenerator(\n",
    "    vocabularySize = 8,\n",
    "    contextSize = 4,\n",
    "    changeResolution = 0.2,\n",
    "    sampleSize = 10,\n",
    "    beta = Double.PositiveInfinity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the main paper, pair generators work not by directly generating pairs of agents with a specific level of ambiguity and asymmetry. They create an proxy parameter space for which pairs of agents can be directly generated. Eventually, theses pairs of agents are grouped by ambiguity and asymmetry. We can access the parameterspace as follows using `.generateParameterSpace` which returns a `Vector` with all combinations of parameters. In this case, `ParametersUniform` consists of:\n",
    "* `agent1Ambiguity`, the ambiguity of the lexicon of agent 1\n",
    "* `agent2Ambiguity`, the ambiguity of the lexicon of agent 2 (only used in specific case)\n",
    "* `changeRate`, the rate with which to change the lexicon of agent 1 to generate the lexicon of agent 2\n",
    "\n",
    "What these parameters do, we will see momentarily. For now, we can observe how `changeResolution` affects the parameter space and how all levels of ambiguity (which depend on `contextSize`) are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val paramSpace = cpg.generateParameterSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function `generatePair` we can generate a pair of agents `AgentPair(agent1, agent2, originData)` for any point in the parameter space. `UniformPairGenerator` does this as follows:\n",
    "1. For agent1, generate a random lexicon with specific ambiguity using `Lexicon.generateConsistentAmbiguityMapping(..)`\n",
    "2. At random, select on of four methods to generate a lexicon for `agent2`:\n",
    "  1. `removalBinaryMutation`, for each $s\\in V$ add a proportion of signal-referent relations to the lexicon based on `changeRate`\n",
    "  2. `additiveBinaryMutation`, for each $s\\in V$ remove a proportion of signal-referent relations from the lexicon based on `changeRate`\n",
    "  3. `mixReferents`, for each $s\\in V$ switch a proportion of signal-referent relations around the lexicons central axis (i.e., `(i)(j) <=>(i)(contextSize-j)`).\n",
    "  4. `generateConsistentAmbiguityMapping`, generates a lexicon for `agent2` from scratch\n",
    "3. Several parameters pertaining to the generation for each pair of agents is stored in `originData` for later reference.\n",
    "\n",
    "The next code chunk selects a random point in the parameter space and generates a pair of agents for it. We can inspect the origin data to see which of the four methods was selected and what the `changeRate` was set to. We can also compute the ambiguity and asymmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val parameters = paramSpace(scala.util.Random.nextInt(paramSpace.size))\n",
    "\n",
    "val pair = cpg.generatePair(parameters)\n",
    "\n",
    "val agent1Ambiguity = pair.agent1.originalLexicon.meanAmbiguity()\n",
    "val agent2Ambiguity = pair.agent2.originalLexicon.meanAmbiguity()\n",
    "val asymmetry = pair.agent1.originalLexicon.asymmetryWith(pair.agent2.originalLexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the simulation\n",
    "The next code chunk demonstrators how we can use Scala's `map` and `flatMap` functions to setup the generation of `sampleSize` agent pairs per point in the parameter space. First, we transform (map) each point in the parameter space to a generator. The generators are iterators over `sampleSize` number of pairs in that point in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sampleGenerators = paramSpace.map(parameters => cpg.sampleGenerator(parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we map each generator (for each point in the parameter space) to an iterator over interactions (for each point in the parameter space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val interactions = sampleGenerators.map(generator => {\n",
    "    // For each generator, we extract all pairs it generates and map those to a sequence of interactions.\n",
    "    // One at order zero (default) and one at order 1. I.e., all agent pairs in the simulation interact\n",
    "    // at multiple orders of pragmatic inference.\n",
    "    generator.flatMap(pair => {\n",
    "        val interaction = RSA1ShotInteraction(pair.agent1, pair.agent2, pair.originData, maxTurns=4)\n",
    "        Seq(interaction, interaction.atOrder(1))\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a large sequence of interactions covering as many points in the parameter space as possible, we can map each interaction to its concluding results by running the interaction through `runAndCollectData`. This returns a sequence of `RSA1InteractionData`, which contains logs for each interaction:\n",
    "* `pairId`, a number identifying the pair of agents\n",
    "* `agent1Order`, the order of agent 1\n",
    "* `agent2Order`, the order of agent 2\n",
    "* `agent1AmbiguityMean`, the mean ambiguity of agent 1's lexicon\n",
    "* `agent1AmbiguityVar`, the mean ambiguity of agent 2's lexicon\n",
    "* `agent2AmbiguityMean`, the variance of ambiguity of agent 1's lexicon\n",
    "* `agent2AmbiguityVar`, the variance of ambiguity of agent 2's lexicon\n",
    "* `asymmetry`, the asymmetry between the agents' lexicons\n",
    "* `originData`, parameters used to generate the agents' lexicons\n",
    "* `interaction`, a list containing logs of interaction between the agents\n",
    "\n",
    "At this stage, the simulation is done and all that is left is to transform the data into a form that is suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val data = interactions.flatMap(interaction => interaction.map(_.runAndCollectData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summarizing the data\n",
    "Since the main dependent measure is average communicative success of pairs of agents, we will need to summarize the agents' interactions in that manner. At the same time, we will flatten the hierarchical data structure returned in the previous step which enables us to export it to a flat `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.markblokpoel.lanag.ambiguityhelps.experiments.uniform.DataFlatUniform\n",
    "\n",
    "val flatData = data.map(d => {\n",
    "    DataFlatUniform(\n",
    "          d.pairId,\n",
    "          d.agent1Order,\n",
    "          d.agent2Order,\n",
    "          d.agent1AmbiguityMean,\n",
    "          d.agent1AmbiguityVar,\n",
    "          d.agent2AmbiguityMean,\n",
    "          d.agent2AmbiguityVar,\n",
    "          d.asymmetry,\n",
    "          cpg.decodeChangeMethod(d.originData.parameter1),\n",
    "          d.originData.parameter2,\n",
    "          averageSuccess = d.interaction.count(i => i.success) / d.interaction.length.toDouble,\n",
    "          averageEntropyAsSpeaker = d.interaction.foldLeft(0.0)((acc, e) =>\n",
    "            acc + e.speakerData.speakerEntropy.getOrElse(0.0)) / d.interaction.length.toDouble,\n",
    "          averageEntropyAsListener = d.interaction.foldLeft(0.0)((acc, e) =>\n",
    "            acc + e.listenerData.listenerEntropy.getOrElse(0.0)) / d.interaction.length.toDouble\n",
    "      )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can write each `DataFlatUniform` in `flatData` to a line in a `.csv` file, which is exactly what is done when using the software from command line. To display the results of our simulation in the notebook, we need to do some additional work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val subset = flatData.filter(d => d.agent1AmbiguityMean == 3 && d.agent2AmbiguityMean == 3)\n",
    "\n",
    "val xdata = subset.map(_.asymmetry).toSet.toList.sorted\n",
    "\n",
    "val groups = subset.groupBy(d => {\n",
    "  if(xdata.contains(d.asymmetry)) d.asymmetry\n",
    "})\n",
    "\n",
    "val xydata = for(x <- xdata) yield {\n",
    "  x -> groups(x).map(pt => pt.averageSuccess).sum.toDouble / groups(x).size\n",
    "}\n",
    "\n",
    "val trace1 = Scatter(\n",
    "    xydata.map(_._1).toSeq,\n",
    "    xydata.map(_._2).toSeq,\n",
    "    mode = ScatterMode(ScatterMode.Lines)\n",
    ")\n",
    "val plotData = Seq(trace1)\n",
    "\n",
    "plot(plotData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
