{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive simulation tutorial part 1: RSA\n",
    "\n",
    "This tutorial is intended to give an introduction to Rational Speech Act (RSA) agents within the Lanag simulation framework. It is part of the Supplementary Information for *submitted*, which we will refer to as the *main paper*.\n",
    "\n",
    "## 1. Loading libraries\n",
    "First we need to load some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import $ivy.`com.markblokpoel::lanag-core:0.3.6`\n",
    "interp.load.cp(new java.net.URL(\"https://github.com/markblokpoel/lanag-ambiguityhelps/blob/jupyternotebooks/binaries/lanag-ambiguityhelps-0.1.jar?raw=true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.markblokpoel.lanag.rsa.Lexicon\n",
    "import com.markblokpoel.lanag.core.ReferentialIntention\n",
    "import com.markblokpoel.lanag.ambiguityhelps._\n",
    "com.markblokpoel.lanag.jupyterdisplayers.LanagCoreDisplayers // Activates nice html printing\n",
    "com.markblokpoel.lanag.ambiguityhelps.jupyterdisplayers.RSA1ShotDisplayers // Activates nice html printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RSA agent\n",
    "\n",
    "In the Rational Speech Act model, an agent’s lexicon is defined by a (possibly) graded mapping between a set of signals and a set of referents. This mapping is encoded in a matrix, where each column represents a referent, and each row represents a signal. An agent is defined by its matrix and its order of pragmatic inference.\n",
    "\n",
    "In this tutorial we will follow the example from the main paper *submitted* about two friends (`friend1` and `friend2`) talking about two classmates whos names they may not know. The snippet below illustrates how a zero order agent can be defined. This agent has a vocabulary $V=\\{\\text{red hair},\\text{tall one},\\text{gamer}\\}$ and a referent set $R=\\{\\text{Nora},\\text{Asla}\\}$. You will notice that the labels of the signals and referents are not present in the simulation code, as these are for our current purpose not important.\n",
    "\n",
    "| &nbsp; |  Nora  |  Asla |\n",
    "|---|--------|-------|\n",
    "| *red hair* | 1 | 0 |\n",
    "| *tall one* | 0 | 1 |\n",
    "| *gamer*    | 1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mapping = Vector[Vector[Double]](\n",
    "  Vector(1,0),\n",
    "  Vector(0,1),\n",
    "  Vector(1,1)\n",
    ")\n",
    "val lexicon = Lexicon(mapping)\n",
    "val friend1 = new RSA1ShotAgent(lexicon, order = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the agent to engage its pragmatic reasoning capacity, we need to tell the simulation framework if the agent is a speaker or a listener. This is done by calling the function `.asSpeaker` or `.asListener` on the object which return a new object where the agent is a speaker or listener. This will internally perform pragmatic inference (based on RSA, see Formulas 1–6 in the main paper) at the specified order to compute a conditional probability mapping. This mapping can be accessed with `.inferredLexicon`.\n",
    "\n",
    "*If you are running this notebook interactively, you can play around with the map and the order to see how this changes the conditional probability mapping. For example, try setting order to 1 and then 2 or change the agent’s lexicon.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val friend1AsListener = friend1.asListener\n",
    "val friend1AsSpeaker = friend1.asSpeaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Zero order speaker and communicator\n",
    "\n",
    "`friend1`'s zero order inferred lexicon consists of\n",
    "probability distributions for signals over referents. For order zero this\n",
    "is computed by normalizing over rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend1.withOrder(0).asListener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speakers, the inferred lexicon consists of distributions over signals. It is computed by normalizing over columns. Here is `friend§`'s inferred lexicon at order zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend1.withOrder(0).asSpeaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Producing a signal\n",
    "Let's make `friend1` communicate a selected intention using `.produceSignal(.)`. This function returns two objects, the selected signal and some data. We will ignore the data for now. In a moment, we will create a friend that will try to intepret the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val intention = 0\n",
    "val speaker = friend1.asSpeaker\n",
    "val refIntention = ReferentialIntention(intention)\n",
    "val (signal, data) = speaker.produceSignal(refIntention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(s\"`friend1` communicates referent $$R_$intention$$ using signal $$S_${signal.content.get}$$.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 How `produceSignal` works\n",
    "The function `produceSignal` does two things. First, it transforms an intention into a distribution over intentions $Pr(R)$, where the intention has probability 1. Next, it computes a posterior distribution over signals given a referent by computing the dot product between the distribution and the $n^\\text{th}$-order inferred lexicon. Then it selects a signal using the softmax function. Here, we set beta to infinite, always selecting the signal with the highest probability (or at random if multiple signals have highest probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.markblokpoel.lanag.math.Probability.softArgMax\n",
    "val intentionDistribution = Vector.tabulate(speaker.originalLexicon.contextSize)(n => if (n == intention) 1.0 else 0.0)\n",
    "val posteriorDistribution = speaker.inferredLexicon dot intentionDistribution\n",
    "softArgMax(posteriorDistribution, beta = Double.PositiveInfinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Exploring speaker behaviour\n",
    "*This section assumes you are running this notebook interactively.*\n",
    "\n",
    "The lines of code below are all we need to explore `friend1`'s behaviour as a speaker. You can change the order of pragmatic reasoning and try different intentions to explore how they affect the speaker's inferred lexicon and produced signals.\n",
    "\n",
    "> You may have noticed objects `Option`, `Some` and `None` pop up in the code or results. This construct is used when a function may not be able to return a value. For example, calling `softArgMax` on an empty distribution will result in a `None`. To 'get' a value from an option-wrapped value, you can use `.get` or better `.getOrElse(x)`, where x is the returned value if called on `None`.\n",
    "\n",
    "\n",
    "Here are some questions to guide your exploration of speaker behaviour:\n",
    "\n",
    "1. What signal has the highest probability given that intention 0?\n",
    "\n",
    "2. If you run the same intention multiple times, does the outcome change and why?\n",
    "\n",
    "3. As a zero order agent, `friend1` cannot reason about the ambiguity in her lexicon and hence when multiple signal options are valid, she selects a signal at random from them. Try setting the order to 1 and observe how both the inferred lexicon and selected signals change.\n",
    "\n",
    "5. With `friend1` as a higher order speaker, try running the code multiple times with the same intention. Observe that for a higher order speaker with this particular lexicon, there is a clear better signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val speaker = friend1.withOrder(0).asSpeaker\n",
    "val (signal, data) = speaker.produceSignal(ReferentialIntention(0))\n",
    "\n",
    "Markdown(s\"The selected signal is $$S_${signal.content.get}$$.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A second agent\n",
    "Let's create a partner for our friend creatively called `friend2`. For now, we give this agent the same lexicon as `friend1`, but it could be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val friend2 = new RSA1ShotAgent(friend1.originalLexicon, order = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make `friend2` the listener of the two. Let’s see how `friend2` would interpret a signal generated by `friend1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val listener = friend2.withOrder(0).asListener\n",
    "val speaker = friend1.withOrder(0).asSpeaker\n",
    "val intention = 0\n",
    "val (signal,_) = speaker.produceSignal(ReferentialIntention(intention))\n",
    "val (inferredIntention,_) = listener.interpretSignal(signal)\n",
    "\n",
    "Markdown(s\"\"\"\n",
    "`friend1` communicates referent $$R_$intention$$ using signal $$S_${signal.content.get}$$.\n",
    "\n",
    "`friend2` infers referent $$R_${inferredIntention.content.get}$$.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With two zero-order communicators, there is more chance for misunderstanding. If you run the example multiple times you can observe this.\n",
    "\n",
    "You can again try to play around with the parameters:\n",
    "\n",
    "1. Try setting the order to 1 and see what happens. Can both agents successfully disambiguate their lexicons?\n",
    "\n",
    "2. Try setting the order to 2 or 4, does this help over and above 1st order?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interaction\n",
    "The simulation framework provide an architecture for two agents to communicate. Below is example code how to set up such an interaction, simulate it and print the data. There is some redundancy with the code above for completeness sake of the example.\n",
    "\n",
    "First we create two agents, each with their own lexicon. Note that the example lexicons are now different, you can play around with them too. Add more signals, more referents, change the relationships and see how this affects the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val lexicon1 = Lexicon(\n",
    "    Vector[Vector[Double]](\n",
    "        Vector(1,0),\n",
    "        Vector(0,1),\n",
    "        Vector(1,1)\n",
    "))\n",
    "val friend1 = new RSA1ShotAgent(lexicon1, order = 0)\n",
    "\n",
    "val lexicon2 = Lexicon(\n",
    "    Vector[Vector[Double]](\n",
    "        Vector(1,0),\n",
    "        Vector(1,1),\n",
    "        Vector(0,1)\n",
    "))\n",
    "val friend2 = new RSA1ShotAgent(lexicon2, order = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two agents, we can set up a repeated 1-shot interaction between them. Here, they will take turns as speaker and listener where they will try to communicate a randomly selected intention each turn. Running the interaction will return a dataset that contains information regarding the interaction between the two agents. The more complex code below is just to extract the data for display. For more information on the contents of the dataset, we refer to the API documentation on [`RSA1InteractionData`](https://markblokpoel.github.io/lanag-ambiguityhelps/latest/api/com/markblokpoel/lanag/ambiguityhelps/RSA1ShotDataStructures$$RSA1InteractionData.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val interaction = new RSA1ShotInteraction(friend1.withOrder(0), friend2.withOrder(0), maxTurns=10)\n",
    "val data = interaction.runAndCollectData\n",
    "\n",
    "Markdown(s\"\"\"\n",
    "### Simulation results\n",
    "\n",
    "|Variable|Value|\n",
    "|---|---|\n",
    "|`friend1`'s ambiguity|${data.agent1AmbiguityMean}|\n",
    "|`friend2`'s ambiguity|${data.agent2AmbiguityMean}|\n",
    "|`friend1`'s order|${data.agent1Order}|\n",
    "|`friend2`'s order|${data.agent2Order}|\n",
    "|asymmetry | ${friend1.originalLexicon.asymmetryWith(friend2.originalLexicon)}\n",
    "|mean success|${data.interaction.count(d => d.success)/data.interaction.length.toDouble*100}%|\n",
    "|number of rounds|${data.interaction.length}|\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
